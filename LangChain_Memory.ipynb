{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":64151,"status":"ok","timestamp":1717128751488,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"yb172S4aDFKS","outputId":"4e651249-e2a1-4281-b84a-796396a2091f"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/320.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/320.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.5/973.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.2/310.2 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.9/168.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","transformers 4.41.1 requires tokenizers\u003c0.20,\u003e=0.19, but you have tokenizers 0.15.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install openai --quiet\n","!pip install langchain --quiet\n","!pip install cohere --quiet\n","!pip install tiktoken --quiet\n","!pip install langchain_community --quiet"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":480,"status":"ok","timestamp":1717128821202,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"iE1mMtv1C5NM"},"outputs":[],"source":["import os\n","os.environ['OPENAI_API_KEY'] = \"sk-classroom-KrqcR03WXZdw0yAZ4PHmT3BlbkFJwetP384cLdDigTAiu5j7\"\n","os.environ[\"COHERE_API_KEY\"] = \"Sy0VwQX4VbA0LQwgr9i8S3fwu3V1xDUbYvdiLFZJ\""]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":760,"status":"ok","timestamp":1717128777081,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"pY6qEt4kY4gZ"},"outputs":[],"source":["from langchain.llms import OpenAI"]},{"cell_type":"markdown","metadata":{"id":"btiPFnoDK5yp"},"source":["# Memory in Langchain"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1848,"status":"ok","timestamp":1717128825886,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"BO6wD-TLYVPJ","outputId":"0a1fbd40-f8df-42ae-9a15-b3652af6223e"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","India won the t20 cricket World Cup in 2007.\n","\n","\n","1. Lionel Messi\n","2. Sergio Aguero\n","3. Angel Di Maria\n","4. Paulo Dybala\n","5. Nicolas Otamendi\n","6. Gonzalo Higuain\n","7. Javier Mascherano\n","8. Marcos Rojo\n","9. Ever Banega\n","10. Mauro Icardi\n","11. Leandro Paredes\n","12. Lucas Biglia\n","13. Eduardo Salvio\n","14. Cristian Pavon\n","15. Gabriel Mercado\n"]}],"source":["llm= OpenAI(temperature=0, max_tokens=512)\n","\n","print(llm.invoke(\"When did India win the t20 cricket World Cup? \"))\n","print(llm.invoke(\"Give me some players in that team\"))"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2392,"status":"ok","timestamp":1717128879231,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"7anSn21s2q8H","outputId":"05b8b1b3-5b59-421f-f459-197cd0aea4bf"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","India won the hockey world cup in 1975.\n","\n","\n","1. Lionel Messi\n","2. Sergio Aguero\n","3. Angel Di Maria\n","4. Paulo Dybala\n","5. Nicolas Otamendi\n","6. Gonzalo Higuain\n","7. Javier Mascherano\n","8. Marcos Rojo\n","9. Ever Banega\n","10. Mauro Icardi\n","11. Leandro Paredes\n","12. Lucas Biglia\n","13. Eduardo Salvio\n","14. Cristian Pavon\n","15. Gabriel Mercado\n"]}],"source":["print(llm.invoke(\"When did India win the hockey worldcup? \"))\n","print(llm.invoke(\"Give me some players in that team\"))"]},{"cell_type":"markdown","metadata":{"id":"ypy4zF3R8D00"},"source":["## ConversationBufferMemory\n","\n","most commonly used.\n","Good for 10 conversations"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":476,"status":"ok","timestamp":1717128895020,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"gzOa5W4171qX"},"outputs":[],"source":["from langchain_community.chat_models import ChatOpenAI\n","from langchain.memory import ConversationBufferMemory\n","from langchain.chains import ConversationChain"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6862,"status":"ok","timestamp":1717129894033,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"fSRIYudo8f8c","outputId":"aef2089b-402f-49a3-d04c-3edffc84be16"},"outputs":[{"name":"stdout","output_type":"stream","text":["India won the ICC T20 Cricket World Cup in 2007 and 2011. They defeated Pakistan in the final in 2007 and Sri Lanka in the final in 2011.\n","Some key players in the 2007 and 2011 ICC T20 Cricket World Cup-winning Indian teams were MS Dhoni (captain), Yuvraj Singh, Gautam Gambhir, Virender Sehwag, Harbhajan Singh, Zaheer Khan, and Suresh Raina.\n"," The wicketkeeper in the winning team for both the 2007 and 2011 ICC T20 Cricket World Cup was MS Dhoni.\n","In the 2007 ICC T20 Cricket World Cup final, Gautam Gambhir was the top scorer for India with 75 runs. In the 2011 final, Mahela Jayawardene of Sri Lanka was the top scorer with 103 runs.\n"," In the 2007 ICC T20 Cricket World Cup final, RP Singh was the top wicket-taker for India with 3 wickets. In the 2011 final, Zaheer Khan and Yuvraj Singh were the top wicket-takers for India with 2 wickets each.\n","The 2007 ICC T20 Cricket World Cup final between India and Pakistan was held at the Wanderers Stadium in Johannesburg, South Africa. The 2011 final between India and Sri Lanka took place at the Wankhede Stadium in Mumbai, India.\n"]}],"source":["llm= ChatOpenAI(temperature=0, max_tokens=512)\n","\n","memory = ConversationBufferMemory()\n","\n","conversation = ConversationChain(llm=llm,\n","                                 memory=memory,\n","                                 #verbose=True\n","                                 )\n","print(conversation.predict(input=\"When did India win the t20 cricket World Cup? \"))\n","print(conversation.predict(input=\"Give me some players in that team\"))\n","print(conversation.predict(input=\"Who was the wicketkeeper in the winning team\"))\n","print(conversation.predict(input=\"Who scored the maximum number of runs in the match\"))\n","print(conversation.predict(input=\"Who took the maximum number of wickets in the match\"))\n","print(conversation.predict(input=\"Give me the name of the cricket ground were the match was held\"))"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3091,"status":"ok","timestamp":1717129899577,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"0w5raSuc4yHZ","outputId":"e69e3716-d828-477f-ebdb-7346984b2435"},"outputs":[{"name":"stdout","output_type":"stream","text":["The umpires for the 2007 ICC T20 Cricket World Cup final between India and Pakistan were Billy Bowden and Rudi Koertzen. In the 2011 final between India and Sri Lanka, the umpires were Simon Taufel and Aleem Dar.\n"," The third umpire for the 2007 ICC T20 Cricket World Cup final was Steve Bucknor. In the 2011 final, the third umpire was Ian Gould.\n","The 2007 ICC T20 Cricket World Cup final between India and Pakistan was held on September 24, 2007. The 2011 final between India and Sri Lanka took place on April 2, 2011.\n"]}],"source":["print(conversation.predict(input=\"Who were the umpires in the match\"))\n","print(conversation.predict(input=\"Who was the third umpire in the match\"))\n","print(conversation.predict(input=\"what was the date\"))\n"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":463,"status":"ok","timestamp":1717129909918,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"O_3huMhH5uM7","outputId":"ca4a853d-3eba-4361-b470-b9e588576ba0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Human: When did India win the t20 cricket World Cup? \n","AI: India won the ICC T20 Cricket World Cup in 2007 and 2011. They defeated Pakistan in the final in 2007 and Sri Lanka in the final in 2011.\n","Human: Give me some players in that team\n","AI: Some key players in the 2007 and 2011 ICC T20 Cricket World Cup-winning Indian teams were MS Dhoni (captain), Yuvraj Singh, Gautam Gambhir, Virender Sehwag, Harbhajan Singh, Zaheer Khan, and Suresh Raina.\n","Human: Who was the wicketkeeper in the winning team\n","AI:  The wicketkeeper in the winning team for both the 2007 and 2011 ICC T20 Cricket World Cup was MS Dhoni.\n","Human: Who scored the maximum number of runs in the match\n","AI: In the 2007 ICC T20 Cricket World Cup final, Gautam Gambhir was the top scorer for India with 75 runs. In the 2011 final, Mahela Jayawardene of Sri Lanka was the top scorer with 103 runs.\n","Human: Who took the maximum number of wickets in the match\n","AI:  In the 2007 ICC T20 Cricket World Cup final, RP Singh was the top wicket-taker for India with 3 wickets. In the 2011 final, Zaheer Khan and Yuvraj Singh were the top wicket-takers for India with 2 wickets each.\n","Human: Give me the name of the cricket ground were the match was held\n","AI: The 2007 ICC T20 Cricket World Cup final between India and Pakistan was held at the Wanderers Stadium in Johannesburg, South Africa. The 2011 final between India and Sri Lanka took place at the Wankhede Stadium in Mumbai, India.\n","Human: Who were the umpires in the match\n","AI: The umpires for the 2007 ICC T20 Cricket World Cup final between India and Pakistan were Billy Bowden and Rudi Koertzen. In the 2011 final between India and Sri Lanka, the umpires were Simon Taufel and Aleem Dar.\n","Human: Who was the third umpire in the match\n","AI:  The third umpire for the 2007 ICC T20 Cricket World Cup final was Steve Bucknor. In the 2011 final, the third umpire was Ian Gould.\n","Human: what was the date\n","AI: The 2007 ICC T20 Cricket World Cup final between India and Pakistan was held on September 24, 2007. The 2011 final between India and Sri Lanka took place on April 2, 2011.\n"]}],"source":["print(conversation.memory.buffer)"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":451,"status":"ok","timestamp":1717129841841,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"x2P7QgTE549J"},"outputs":[],"source":["def ClearMemory():\n","\n","    conversation.memory.clear()\n",""]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1717129869755,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"zbIkapun6he8","outputId":"86008743-996f-4b78-8a35-9aa72101c2c7"},"outputs":[{"data":{"text/html":["\u003cdiv style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"\u003e\u003cstyle\u003e\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    \u003c/style\u003e\n","    \u003cpre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"\u003e\u003cb\u003eClearMemory\u003c/b\u003e\u003cbr/\u003edef ClearMemory()\u003c/pre\u003e\u003cpre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"\u003e\u003ca class=\"filepath\" style=\"display:none\" href=\"#\"\u003e/content/\u0026lt;ipython-input-28-c90a4f608b40\u0026gt;\u003c/a\u003e\u0026lt;no docstring\u0026gt;\u003c/pre\u003e\u003c/div\u003e"],"text/plain":["\u003cfunction __main__.ClearMemory()\u003e"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["ClearMemory"]},{"cell_type":"markdown","metadata":{"id":"RpHLvo5ZPC6V"},"source":["## With Verbose=True"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2752,"status":"ok","timestamp":1717129931185,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"kEDfyccEPFsd","outputId":"dd4ef208-8509-4d77-cbe1-001610df5828"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m\u003e Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","\n","Human: When did India win the t20 cricket World Cup? \n","AI:\u001b[0m\n","\n","\u001b[1m\u003e Finished chain.\u001b[0m\n","India won the ICC T20 Cricket World Cup in 2007 and 2011. They defeated Pakistan in the final in 2007 and Sri Lanka in the final in 2011.\n","\n","\n","\u001b[1m\u003e Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","Human: When did India win the t20 cricket World Cup? \n","AI: India won the ICC T20 Cricket World Cup in 2007 and 2011. They defeated Pakistan in the final in 2007 and Sri Lanka in the final in 2011.\n","Human: Give me some players in that team\n","AI:\u001b[0m\n","\n","\u001b[1m\u003e Finished chain.\u001b[0m\n","Some key players in the 2007 and 2011 ICC T20 Cricket World Cup-winning Indian teams were MS Dhoni (captain), Yuvraj Singh, Gautam Gambhir, Virender Sehwag, Harbhajan Singh, Zaheer Khan, and Suresh Raina.\n"]}],"source":["llm= ChatOpenAI(temperature=0, max_tokens=512)\n","\n","memory = ConversationBufferMemory()\n","\n","conversation = ConversationChain(llm=llm,\n","                                 memory=memory,\n","                                 verbose=True\n","                                 )\n","print(conversation.predict(input=\"When did India win the t20 cricket World Cup? \"))\n","print(conversation.predict(input=\"Give me some players in that team\"))"]},{"cell_type":"markdown","metadata":{"id":"o810g19hW9HU"},"source":["### What happens behind the scenes?"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":469,"status":"ok","timestamp":1717129935134,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"WZIZ074aW0sV","outputId":"d31b80d5-7eea-4d73-edc2-9667e227805a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Human: When did India win the t20 cricket World Cup? \n","AI: India won the ICC T20 Cricket World Cup in 2007 and 2011. They defeated Pakistan in the final in 2007 and Sri Lanka in the final in 2011.\n","Human: Give me some players in that team\n","AI: Some key players in the 2007 and 2011 ICC T20 Cricket World Cup-winning Indian teams were MS Dhoni (captain), Yuvraj Singh, Gautam Gambhir, Virender Sehwag, Harbhajan Singh, Zaheer Khan, and Suresh Raina.\n"]}],"source":["print(conversation.memory.buffer)"]},{"cell_type":"markdown","metadata":{"id":"7qlz4E-CPGTd"},"source":["## Memory Example-2"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87},"executionInfo":{"elapsed":2910,"status":"ok","timestamp":1717129941601,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"VhTgmXyuOmBh","outputId":"564ade2b-0f76-4587-e8c8-65e0fca85f6f"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Sure! The main differences between Classification and Regression are:\\n\\n1. Output: In Classification, the output variable is a category or a class label, while in Regression, the output variable is a continuous value.\\n\\n2. Goal: The goal of Classification is to predict the class label of a new instance, while the goal of Regression is to predict a continuous value for a new instance.\\n\\n3. Evaluation: In Classification, evaluation metrics like accuracy, precision, recall, and F1 score are used to measure the performance of the model, while in Regression, evaluation metrics like Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and R-squared are used.\\n\\nThese are the three main differences between Classification and Regression. Let me know if you have any more questions!'"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["llm= ChatOpenAI(temperature=0, max_tokens=512)\n","\n","memory = ConversationBufferMemory()\n","\n","conversation = ConversationChain(llm=llm,\n","                                 memory=memory,\n","                                 #verbose=True\n","                                 )\n","conversation.predict(input=\"Explain three main differences Classification and Regression\")"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"elapsed":2215,"status":"ok","timestamp":1717129946280,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"zEdXZrc49XdV","outputId":"77cde29d-6109-4f40-d1aa-e2f08daa55bc"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Of course! Here is the information in markdown tabular code format:\\n\\n| Difference      | Classification | Regression |\\n|-----------------|----------------|------------|\\n| Output          | Category or class label | Continuous value |\\n| Goal            | Predict class label of new instance | Predict continuous value for new instance |\\n| Evaluation      | Accuracy, precision, recall, F1 score | Mean Squared Error (MSE), Root Mean Squared Error (RMSE), R-squared | \\n\\nI hope this format helps! Let me know if you need any more information.'"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["conversation.predict(input=\"Give the above output in markdown tabular code format \")"]},{"cell_type":"markdown","metadata":{"id":"VjMfwfGzAc7o"},"source":["  | Main Differences | Classification | Regression |\n","| --- | --- | --- |\n","| Type of Learning | Supervised | Supervised |\n","| Predicted Values | Categorical or discrete | Continuous numerical |\n","| Techniques | Decision trees, support vector machines, neural networks | Linear regression, logistic regression, polynomial regression |\n","| Evaluation Metrics | Accuracy, precision, recall | Mean squared error, mean absolute error, R-squared |"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uUcAWphy9mGx"},"outputs":[],"source":["conversation.predict(input=\"Which one is most widely used in predicting customer churn?\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sCKFcBDI90xL"},"outputs":[],"source":["conversation.predict(input=\"Give me one more difference\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s6hvFhF6BRK2"},"outputs":[],"source":["#What happens behind the scenes?\n","print(conversation.memory.buffer)"]},{"cell_type":"markdown","metadata":{"id":"QdSPeHmsUoJ4"},"source":["## ConversationSummaryMemory"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":1496,"status":"ok","timestamp":1717129951440,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"ZiPXoA0YCT6x","outputId":"d0dc2729-0732-45e2-d699-340250f6134a"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"Hello! I'd be happy to help you with your order. Can you please provide me with your order number so I can look up the details for you?\""]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["from langchain.chains.conversation.memory import ConversationSummaryMemory\n","\n","memory = ConversationSummaryMemory(llm=llm)\n","\n","conversation = ConversationChain(llm=llm, memory=memory)\n","conversation.predict(input=\"Hello, I need help with my order\")"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":2363,"status":"ok","timestamp":1717129957761,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"xbkNDQChUADo","outputId":"36a966c7-72c7-4509-d646-9f667afb0cec"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Great! I can help you with that. Can you please provide me with the order number so I can look up the details for you?'"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["conversation.predict(input=\"I ordered a pizza\")"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":2731,"status":"ok","timestamp":1717129965912,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"6t6jolCMUIyz","outputId":"6fb4d67b-aa90-4c62-d497-00f28a3bfdf1"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'No problem! Do you remember when you placed the order or any specific toppings you requested on the pizza? That might help me narrow down the search.'"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["conversation.predict(input=\"I don't remember the order details\")"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":506,"status":"ok","timestamp":1717129974429,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"MsK75HS8UgDB","outputId":"0ba044d2-1468-47de-d239-a2e21ebfe37f"},"outputs":[{"name":"stdout","output_type":"stream","text":["The human asks for help with their order, mentioning they ordered a pizza. The AI offers to assist and asks for the order number. The human doesn't remember the order details, but the AI suggests remembering when the order was placed or specific toppings requested on the pizza to narrow down the search.\n"]}],"source":["print(conversation.memory.buffer)"]},{"cell_type":"markdown","metadata":{"id":"-7UbWDAsP-gI"},"source":["## ConverstationEntitySummary"]},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":473,"status":"ok","timestamp":1717130963052,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"IgEGRiTfRUHk"},"outputs":[],"source":["from langchain.chains.conversation.memory import ConversationEntityMemory\n","from langchain.chains.conversation.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE\n","from langchain.prompts.prompt import PromptTemplate\n","from pydantic import BaseModel, Field\n","from typing import List, Optional, Dict, Any"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1717130966536,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"DCk4YwWPR5SE","outputId":"6aed40f4-aea2-4b7a-c77e-72d76c4d5695"},"outputs":[{"name":"stdout","output_type":"stream","text":["You are an assistant to a human, powered by a large language model trained by OpenAI.\n","\n","You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n","\n","You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n","\n","Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n","\n","Context:\n","{entities}\n","\n","Current conversation:\n","{history}\n","Last line:\n","Human: {input}\n","You:\n"]}],"source":["template=ENTITY_MEMORY_CONVERSATION_TEMPLATE.template\n","print(template)"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":437},"executionInfo":{"elapsed":2396,"status":"ok","timestamp":1717130990529,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"_x7qSkN7QBqa","outputId":"8edc10da-4341-4531-db4a-88b58b3c601c"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m\u003e Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n","\n","You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n","\n","You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n","\n","Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n","\n","Context:\n","{'Venkat': '', 'Bangalore': ''}\n","\n","Current conversation:\n","\n","Last line:\n","Human: Hello, My Name is Venkat. I am from Bangalore. I need help with my order\n","You:\u001b[0m\n","\n","\u001b[1m\u003e Finished chain.\u001b[0m\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"Hello Venkat! I'm here to help you with your order. Please provide me with more details about your order so I can assist you better.\""]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["memory = ConversationEntityMemory(llm=llm)\n","conversation = ConversationChain(llm=llm,\n","                                 memory=memory,\n","                                 verbose=True,\n","                                 prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE)\n","conversation.predict(input=\"Hello, My Name is Venkat. I am from Bangalore. I need help with my order\")"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":455},"executionInfo":{"elapsed":1530,"status":"ok","timestamp":1717130996867,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"h4aPc45rRB0F","outputId":"027fa98e-5720-45fe-f1f0-d0806702629e"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m\u003e Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n","\n","You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n","\n","You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n","\n","Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n","\n","Context:\n","{'Mobile': ''}\n","\n","Current conversation:\n","Human: Hello, My Name is Venkat. I am from Bangalore. I need help with my order\n","AI: Hello Venkat! I'm here to help you with your order. Please provide me with more details about your order so I can assist you better.\n","Last line:\n","Human: I ordered Mobile phone on tuesday night 8pm\n","You:\u001b[0m\n","\n","\u001b[1m\u003e Finished chain.\u001b[0m\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Great, thank you for providing that information. Can you please let me know what specific help you need with your mobile phone order?'"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["conversation.predict(input=\"I ordered Mobile phone on tuesday night 8pm\")"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":489},"executionInfo":{"elapsed":1952,"status":"ok","timestamp":1717131001993,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"jqgoqGd_S0lG","outputId":"3e45caf1-205f-424d-ac34-9dc64643d199"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m\u003e Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n","\n","You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n","\n","You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n","\n","Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n","\n","Context:\n","{'IBLC19678456': ''}\n","\n","Current conversation:\n","Human: Hello, My Name is Venkat. I am from Bangalore. I need help with my order\n","AI: Hello Venkat! I'm here to help you with your order. Please provide me with more details about your order so I can assist you better.\n","Human: I ordered Mobile phone on tuesday night 8pm\n","AI: Great, thank you for providing that information. Can you please let me know what specific help you need with your mobile phone order?\n","Last line:\n","Human: My order number is IBLC19678456. What is the status of my order?\n","You:\u001b[0m\n","\n","\u001b[1m\u003e Finished chain.\u001b[0m\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Let me check the status of your order with the order number IBLC19678456. Give me a moment to look it up for you.'"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["conversation.predict(input=\"My order number is IBLC19678456. What is the status of my order?\")"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":451,"status":"ok","timestamp":1717131006292,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"YXYMQGG7S2mQ","outputId":"22084683-d3d3-49dd-8298-99e28affcebf"},"outputs":[{"data":{"text/plain":["[HumanMessage(content='Hello, My Name is Venkat. I am from Bangalore. I need help with my order'),\n"," AIMessage(content=\"Hello Venkat! I'm here to help you with your order. Please provide me with more details about your order so I can assist you better.\"),\n"," HumanMessage(content='I ordered Mobile phone on tuesday night 8pm'),\n"," AIMessage(content='Great, thank you for providing that information. Can you please let me know what specific help you need with your mobile phone order?'),\n"," HumanMessage(content='My order number is IBLC19678456. What is the status of my order?'),\n"," AIMessage(content='Let me check the status of your order with the order number IBLC19678456. Give me a moment to look it up for you.')]"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["conversation.memory.buffer"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":469,"status":"ok","timestamp":1717131011159,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"BLGNPWJaTB5G","outputId":"179479f3-5071-46d6-fda8-386c6c7edd37"},"outputs":[{"data":{"text/plain":["InMemoryEntityStore(store={'Venkat': 'Venkat is from Bangalore.', 'Bangalore': 'Bangalore is the location where Venkat is from.', 'Mobile': 'Mobile phones can be ordered on Tuesday nights at 8pm.', 'IBLC19678456': 'The order number IBLC19678456 is being checked for the status update.'})"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["conversation.memory.entity_store"]},{"cell_type":"markdown","metadata":{"id":"VtOyURrOcyfN"},"source":["# Building a Simple Chatbot"]},{"cell_type":"code","execution_count":50,"metadata":{"executionInfo":{"elapsed":457,"status":"ok","timestamp":1717131016529,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"I3vLanZ2Sov6"},"outputs":[],"source":["from langchain import OpenAI, ConversationChain\n","from langchain.chat_models import ChatOpenAI\n","from langchain.memory import ConversationBufferMemory\n"]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":476335,"status":"ok","timestamp":1717131494395,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"wk6BiZ-lc9b6","outputId":"16ce561e-da8f-438d-df66-e933f937bc24"},"outputs":[{"name":"stdout","output_type":"stream","text":["Your message:when did world war 2 end?\n","AI message ==\u003e World War 2 ended on September 2, 1945, when Japan formally surrendered, marking the end of the war.\n","Your message: quit\n"]}],"source":["#Type quit to exit this Conversation\n","user_input=input(\"Your message:\")\n","llm= ChatOpenAI(temperature=0, max_tokens=512)\n","memory = ConversationBufferMemory()\n","conversation = ConversationChain(llm=llm,\n","                                 memory=memory,\n","                                 verbose=False\n","                                 )\n","while user_input!=\"quit\":\n","    print(\"AI message ==\u003e\", conversation.predict(input=user_input))\n","    user_input=input(\"Your message: \")\n","while user_input ==\"quit\":\n","    memory.clear()\n","    break"]},{"cell_type":"markdown","metadata":{"id":"v5HjnCHJwFI9"},"source":["# Example with RAG, Memory and Conversation"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8741,"status":"ok","timestamp":1717131506751,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"iWEpYYzG--Qc","outputId":"db363c5e-7d21-43f7-9ea0-362bf2f9a747"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/290.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/290.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install pypdf --quiet"]},{"cell_type":"code","execution_count":53,"metadata":{"executionInfo":{"elapsed":749,"status":"ok","timestamp":1717131514745,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"4C7Jewx3wlwd"},"outputs":[],"source":["from langchain.chains import ConversationalRetrievalChain\n","from langchain.document_loaders import TextLoader, PyPDFLoader\n","from langchain.embeddings.openai import OpenAIEmbeddings\n","from langchain.llms import OpenAI\n","from langchain.memory import ConversationBufferMemory\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain.vectorstores import Chroma\n","import glob"]},{"cell_type":"markdown","metadata":{"id":"uFoiLWdwCwgj"},"source":["## Step-1 :Data Importing"]},{"cell_type":"code","execution_count":54,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1144,"status":"ok","timestamp":1717131521421,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"dM1yvZvewheE","outputId":"4c46b9ad-abb2-42f3-bda5-680f7ee5a3d2"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2024-05-31 04:58:40--  https://raw.githubusercontent.com/venkatareddykonasani/Datasets/master/CIBIL_Report/All_Cibil_Docs.zip\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2818524 (2.7M) [application/zip]\n","Saving to: ‘All_Cibil_Docs.zip’\n","\n","All_Cibil_Docs.zip  100%[===================\u003e]   2.69M  --.-KB/s    in 0.06s   \n","\n","2024-05-31 04:58:40 (43.1 MB/s) - ‘All_Cibil_Docs.zip’ saved [2818524/2818524]\n","\n","Archive:  All_Cibil_Docs.zip\n","  inflating: All_Docs_Set1/5787-15251-1-PB.pdf  \n","  inflating: All_Docs_Set1/CIBIL Score in India.pdf  \n","  inflating: All_Docs_Set1/creditscoretips_2.pdf  \n","  inflating: All_Docs_Set1/MyCIBIL-Understanding.pdf  \n","  inflating: All_Docs_Set1/understanding-cir-ctc.pdf  \n","['All_Docs_Set1/5787-15251-1-PB.pdf', 'All_Docs_Set1/creditscoretips_2.pdf', 'All_Docs_Set1/MyCIBIL-Understanding.pdf', 'All_Docs_Set1/CIBIL Score in India.pdf', 'All_Docs_Set1/understanding-cir-ctc.pdf']\n"]}],"source":["#Example of ConversationalRetrievalChain\n","\n","#Document Loading\n","!wget https://raw.githubusercontent.com/venkatareddykonasani/Datasets/master/CIBIL_Report/All_Cibil_Docs.zip\n","#Unzip and Overwrite\n","!unzip -o All_Cibil_Docs.zip -d All_Docs_Set1\n","#listdown all documents content/All_Docs_Set1 and store them\n","pdf_files = glob.glob(\"All_Docs_Set1/*.pdf\")\n","print(pdf_files)"]},{"cell_type":"code","execution_count":67,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7503,"status":"ok","timestamp":1717132343571,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"tIevEFt7-11C","outputId":"98ffadc2-a2ae-4c1a-fecd-67183ae7c979"},"outputs":[{"name":"stdout","output_type":"stream","text":["All_Docs_Set1/5787-15251-1-PB.pdf 12\n","All_Docs_Set1/creditscoretips_2.pdf 1\n","All_Docs_Set1/MyCIBIL-Understanding.pdf 4\n","All_Docs_Set1/CIBIL Score in India.pdf 7\n","All_Docs_Set1/understanding-cir-ctc.pdf 3\n","\n","\n","ee discussions, st ats, and author pr ofiles f or this public ation at : https://www .researchgate.ne t/public ation/351979266\n","Awareness of Credit Score Mechanism in India: A Study with reference to\n","Credit Information Bu reau India Limited (CIBIL)\n","Article  · Mar ch 2017\n","CITATIONS\n","0READS\n","3,857\n","2 author s, including:\n","S. Sank aramuthuk umar\n","Bahr ain P olyt echnic\n","18 PUBLICA TIONS    19 CITATIONS    \n","SEE PROFILE\n","All c ontent f ollo wing this p age was uplo aded b y S. Sank aramuthuk umar  on 04 F ebruar y 2023.\n","The user has r equest ed enhanc ement of the do wnlo aded file. \n","  1  Awareness of Credit Score Mechanism in India: A Study with reference to Credit Information Bureau India Limited (CIBIL)  Dr. Saravanan Laxmanan,  Assistant Professor, Department of Management,  College of Business \u0026 Economics, Addi\n","\n","\n","Lines 576\n","Words 10928\n","Charecters 67360\n"]}],"source":["full_text = \"\"\n","for pdf_file in pdf_files:\n","    loader = PyPDFLoader(pdf_file)\n","    pages = loader.load()\n","    print(pdf_file, len(pages))\n","    for page in pages:\n","        full_text += page.page_content\n","\n","print(\"\\n\")\n","print(full_text[1:1000])\n","print(\"\\n\")\n","print(\"Lines\" , len(full_text.split(\"\\n\")))\n","print(\"Words\" , len(full_text.split(\" \")))\n","print(\"Charecters\", len(full_text))"]},{"cell_type":"markdown","metadata":{"id":"6nddR_wGDElT"},"source":["## Step-2:Split the data into Chunks"]},{"cell_type":"code","execution_count":56,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":470,"status":"ok","timestamp":1717131552946,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"t7vJzrSgC1Lb","outputId":"d6495603-d0b6-43e6-8ebe-bef6cf091b52"},"outputs":[{"name":"stdout","output_type":"stream","text":["290\n","See discussions, st ats, and author pr ofiles f or this public ation at : https://www .researchgate.ne t/public ation/351979266\n","Awareness of Credit Score Mechanism in India: A Study with reference to\n","Credit Information Bu reau India Limited (CIBIL)\n","Article  · Mar ch 2017\n","CITATIONS\n","0READS\n","3,857\n"]}],"source":["text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=60)\n","chunks = text_splitter.split_text(full_text)\n","print(len(chunks))\n","print(chunks[0])"]},{"cell_type":"markdown","metadata":{"id":"ciwB4WJlFrr8"},"source":["## Step-3: Creating embeddings and Storing in Vector Stores"]},{"cell_type":"code","execution_count":58,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":34126,"status":"ok","timestamp":1717131593281,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"YPb15teWG1Bk","outputId":"ac54b5d5-1faf-47c4-a19e-544384bcbe42"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.8/526.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","spacy 3.7.4 requires typer\u003c0.10.0,\u003e=0.3.0, but you have typer 0.12.3 which is incompatible.\n","weasel 0.3.4 requires typer\u003c0.10.0,\u003e=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install ChromaDB --quiet"]},{"cell_type":"code","execution_count":59,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5961,"status":"ok","timestamp":1717131599239,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"ssiV5nucAQol","outputId":"16e1ffcf-50f8-4bf1-defa-f26405034794"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n","  warn_deprecated(\n"]}],"source":["embeddings = OpenAIEmbeddings()\n","cibil_db=Chroma.from_texts(chunks,\n","                               embeddings,\n","                               persist_directory=\"cibil_db\")\n","cibil_db.persist()"]},{"cell_type":"code","execution_count":68,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":464,"status":"ok","timestamp":1717132437213,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"p_egFbt8UN4n","outputId":"b523a312-d835-4a3f-d112-589b16d29929"},"outputs":[{"name":"stdout","output_type":"stream","text":["Credit EducationWhat is a CIBIL Score?\n","CIBIL Score is a 3 digit numeric summary of your credit history, derived by using details found in the ‘Accounts’ and ‘Enquiries’\n","Understanding the Basics  \n","1. Introduction to CIBIL Score  \n","The CIBIL Score, developed by the Credit Information Bureau (India) Limited (now \n","TransUnion CIBIL), is a numerical representation of an individual's creditworthiness. It\n","which is widely used by loan providers to evaluate loan applications. An individual’s CIBIL Score ranges between 300-900, and is calculated basis the information in the “Accounts” and “Enquiry” section of the credit report. The closer the score to 900, the more conﬁdence the loan provider will have\n","from credit bureaus. The Credit Information Bureau India Limited (CIBIL) credit score is a three-digit number that represents a summary of individuals' credit history and credit rating. This score ranges from 300 to 900, with 900 being the best score. Individuals with no credit history will have a\n"]}],"source":["retriever = cibil_db.as_retriever()\n","result=retriever.get_relevant_documents(query=\"What is the CIBIL Score?\")\n","for i in range(len(result)):\n","  print(result[i].page_content)"]},{"cell_type":"markdown","metadata":{"id":"Mk2tQsfsFyrs"},"source":["## Step-4: Conversation and Retrieval Chain"]},{"cell_type":"code","execution_count":61,"metadata":{"executionInfo":{"elapsed":450,"status":"ok","timestamp":1717131631272,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"tqMgT-PxJLc2"},"outputs":[],"source":["from langchain.chat_models import ChatOpenAI, cohere\n","from langchain.llms import Cohere"]},{"cell_type":"code","execution_count":62,"metadata":{"executionInfo":{"elapsed":498,"status":"ok","timestamp":1717131633996,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"kLrb6fpwFpk6"},"outputs":[],"source":["llm= ChatOpenAI(temperature=0, max_tokens=512)\n","#llm=Cohere(temperature=0, max_tokens=512)\n","memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n","conversational_RAG = ConversationalRetrievalChain.from_llm(llm=llm,\n","                                                     retriever=cibil_db.as_retriever(),\n","                                                     memory=memory,\n","                                                     #verbose=True\n","                                                     )"]},{"cell_type":"markdown","metadata":{"id":"zr8Bc1ySIIQU"},"source":["## Step-5 : Conversation"]},{"cell_type":"code","execution_count":64,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":92046,"status":"ok","timestamp":1717131830757,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"qqOdnx80FpoT","outputId":"3d9af1d7-9609-4e4c-8055-6f0d38a97f7a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Your message:what is cibil score\n","AI message ==\u003e A CIBIL Score is a 3-digit numeric summary of your credit history, ranging from 300 to 900, that represents your creditworthiness. It is calculated based on the information in the 'Accounts' and 'Enquiries' sections of your credit report and is widely used by loan providers to evaluate loan applications.\n","Your message: how to increase the cibil score\n","AI message ==\u003e To increase your CIBIL score, you can focus on the following strategies:\n","\n","1. **Payment History**: Ensure that you make all your payments on time and avoid defaulting on EMIs or dues. Consistent and timely payments positively impact your score.\n","\n","2. **Credit Utilization**: Try to keep your credit utilization ratio low. Ideally, it is recommended to use less than 30% of your available credit limit.\n","\n","3. **Credit History**: Having a longer credit history with responsible credit use can boost your score. It shows lenders that you have a track record of managing credit well.\n","\n","4. **Regular Monitoring**: Check your credit report annually to identify any errors or discrepancies that may be affecting your score. Correcting these issues can help improve your score over time.\n","\n","By focusing on these factors and following good credit practices, you can gradually increase your CIBIL score.\n","Your message: what is score\n","AI message ==\u003e A CIBIL Score is a 3-digit numeric summary of your credit history, derived from details found in the 'Accounts' and 'Enquiries' sections of your credit report. It is a numerical representation of an individual's creditworthiness, ranging from 300 to 900, with 900 being the best score.\n","Your message: what is cricket score\n","AI message ==\u003e I don't know the cricket score.\n","Your message: does score decrease\n","AI message ==\u003e Yes, a low credit score can decrease an individual's borrowing accessibility and impact their financial planning.\n","Your message: quit\n"]}],"source":["user_input=input(\"Your message:\")\n","while user_input!=\"quit\":\n","    response=conversational_RAG({\"question\": user_input})\n","    print(\"AI message ==\u003e\", response[\"answer\"])\n","    user_input=input(\"Your message: \")"]},{"cell_type":"markdown","metadata":{"id":"DSjFoQYdSCJo"},"source":["# RAG ChatBotTool"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B0lEI8A0QjWO"},"outputs":[],"source":["%%writefile requirements.txt\n","langchain==0.0.184\n","PyPDF2==3.0.1\n","python-dotenv==1.0.0\n","streamlit==1.18.1\n","openai==0.27.6\n","faiss-cpu==1.7.4\n","altair==4\n","tiktoken==0.4.0\n","huggingface-hub==0.14.1\n","InstructorEmbedding==1.0.1\n","sentence-transformers==2.2.2"]},{"cell_type":"code","execution_count":72,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1717133002149,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"cK2ECRfZTcXg"},"outputs":[],"source":["import os\n","os.environ['OPENAI_API_KEY'] = \"sk-classroom-KrqcR03WXZdw0yAZ4PHmT3BlbkFJwetP384cLdDigTAiu5j7\"\n","os.environ['HUGGINGFACEHUB_API_TOKEN']=\"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\"\n","os.environ[\"COHERE_API_KEY\"] = \"GrjMhqpFhFufJQ3Aq6PpDurqHgbgMmbYGbHFN1ql\"\n","os.environ[\"PINECONE_API_KEY\"]=\"9b8d6f39-4fad-423d-be07-c23193563b8b\"\n","os.environ[\"ANTHROPIC_API_KEY\"] = \"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\""]},{"cell_type":"code","execution_count":71,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":144086,"status":"ok","timestamp":1717132992479,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"pXiNMQMJTezd","outputId":"1b31538c-f02b-4582-f61f-702a7c711e45"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.3/939.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m709.0/709.0 kB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.8/164.8 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m99.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cohere 5.5.4 requires tokenizers\u003c0.16,\u003e=0.15, but you have tokenizers 0.13.3 which is incompatible.\n","langchain-community 0.2.1 requires langchain\u003c0.3.0,\u003e=0.2.0, but you have langchain 0.0.184 which is incompatible.\n","spacy 3.7.4 requires typer\u003c0.10.0,\u003e=0.3.0, but you have typer 0.12.3 which is incompatible.\n","weasel 0.3.4 requires typer\u003c0.10.0,\u003e=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install -r requirements.txt --quiet"]},{"cell_type":"code","execution_count":73,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":479,"status":"ok","timestamp":1717133007377,"user":{"displayName":"Charles Theophilus","userId":"16523271150675086603"},"user_tz":-330},"id":"Lb0BtRnzTkc6","outputId":"8e284a5a-b5be-43e7-9d0b-a4191f559b1a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Writing app.py\n"]}],"source":["%%writefile app.py\n","\n","import streamlit as st\n","from PyPDF2 import PdfReader\n","from langchain.text_splitter import CharacterTextSplitter\n","from langchain.embeddings import OpenAIEmbeddings\n","from langchain.vectorstores import FAISS\n","from langchain.chat_models import ChatOpenAI\n","from langchain.chains import ConversationalRetrievalChain\n","from langchain.memory import ConversationBufferMemory\n","\n","\n","def get_pdf_text(pdf_docs):\n","    text = \"\"\n","    for pdf in pdf_docs:\n","        pdf_reader = PdfReader(pdf)\n","        for page in pdf_reader.pages:\n","            text += page.extract_text()\n","    return text\n","\n","def get_text_chunks(text):\n","  text_splitter = CharacterTextSplitter(\n","      separator=\"\\n\",\n","      chunk_size=1000,\n","      chunk_overlap=200,\n","      length_function=len\n","  )\n","  chunks = text_splitter.split_text(text)\n","  return chunks\n","\n","def get_embeddings(text_chunks):\n","  embeddings = OpenAIEmbeddings()\n","  return embeddings\n","\n","def get_convesrational_chain(vectorstore):\n","  llm = ChatOpenAI(temperature=0)\n","  memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n","  convesrational_chain = ConversationalRetrievalChain.from_llm(\n","      llm=llm,\n","      retriever=vectorstore.as_retriever(),\n","      memory=memory\n","  )\n","  return convesrational_chain\n","\n","\n","def handle_userinput(user_question):\n","  response = st.session_state.convesrational_chain({\"question\": user_question})\n","  st.session_state.chat_history = response['chat_history']\n","\n","  for i, message in enumerate(st.session_state.chat_history):\n","    if i % 2 == 0 :\n","      st.write(':man_in_tuxedo:', message.content)\n","    else:\n","      st.write(':robot_face:', message.content)\n","\n","def main():\n","\n","    st.set_page_config(page_title=\"Chat with Documents\", page_icon=\":books:\")\n","    styl = f\"\"\"\n","      \u003cstyle\u003e\n","          .stTextInput {{\n","            position: fixed;\n","            bottom: 3rem;\n","          }}\n","      \u003c/style\u003e\n","      \"\"\"\n","    st.markdown(styl, unsafe_allow_html=True)\n","\n","    #st.write(css, unsafe_allow_html=True)\n","    st.title(\"AI Chat-Bot for Your Documents :books:\")\n","\n","    if \"convesrational_chain\" not in st.session_state:\n","        st.session_state.convesrational_chain = None\n","    if \"chat_history\" not in st.session_state:\n","        st.session_state.chat_history = None\n","\n","\n","    user_input=st.text_input(\"Upload files, Hit Submit button, then ask questions.:blue[- Venkat Reddy]:sunglasses:\")\n","    if user_input:\n","      handle_userinput(user_input)\n","\n","\n","    with st.sidebar:\n","        pdf_docs=st.file_uploader(\"Upload your documents here\" , accept_multiple_files=True)\n","        if st.button(\"Submit\"):\n","          with st.spinner(\"Processing...\"):\n","\n","            # Get PDF Data\n","            raw_text=get_pdf_text(pdf_docs)\n","\n","            #Divide the Data into Chunks\n","            chunked_array=get_text_chunks(raw_text)\n","\n","            #Create embeddings\n","            embeddings=get_embeddings(chunked_array)\n","\n","            #Create vectorstore\n","            vectorstore=FAISS.from_texts(chunked_array,embeddings)\n","\n","            #crate a converstaion chain\n","            st.session_state.convesrational_chain=get_convesrational_chain(vectorstore)\n","\n","\n","\n","if __name__ == \"__main__\":\n","    main()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"YphGHyMITyNq"},"outputs":[{"name":"stdout","output_type":"stream","text":["34.105.11.121\n","\u001b[K\u001b[?25hnpx: installed 22 in 4.692s\n","your url is: https://cold-pans-flow.loca.lt\n","\n","Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n","\u001b[0m\n","\u001b[0m\n","\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n","\u001b[0m\n","\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n","\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.105.11.121:8501\u001b[0m\n","\u001b[0m\n"]}],"source":["!streamlit run app.py \u0026 npx localtunnel --port 8501 \u0026 curl ipv4.icanhazip.com"]}],"metadata":{"colab":{"name":"","provenance":[{"file_id":"1hzW0IU2nIwvBnzvN2YCuIqvA5sa0kRFu","timestamp":1717128639277}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}